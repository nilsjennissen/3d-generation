{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cloned Reporsiotry for Initial Use"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71335b48cec1ab64"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nilsjennissen/PycharmProjects/3d-generation/shap-e/shap-e\n",
      "Obtaining file:///Users/nilsjennissen/PycharmProjects/3d-generation/shap-e/shap-e\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting clip@ git+https://github.com/openai/CLIP.git (from shap-e==0.0.0)\r\n",
      "  Cloning https://github.com/openai/CLIP.git to /private/var/folders/sl/c5pyww8j61j6_9_z4twp2ygc0000gn/T/pip-install-xf_n6nvz/clip_0b22b82c0232431dae36b7dfc0649996\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /private/var/folders/sl/c5pyww8j61j6_9_z4twp2ygc0000gn/T/pip-install-xf_n6nvz/clip_0b22b82c0232431dae36b7dfc0649996\r\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: filelock in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (3.12.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (10.0.0)\r\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (2.0.1)\r\n",
      "Requirement already satisfied: fire in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (0.5.0)\r\n",
      "Requirement already satisfied: humanize in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (4.7.0)\r\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (4.66.1)\r\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (3.7.2)\r\n",
      "Requirement already satisfied: scikit-image in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (0.21.0)\r\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (1.11.1)\r\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (1.25.2)\r\n",
      "Requirement already satisfied: blobfile in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from shap-e==0.0.0) (2.0.2)\r\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from blobfile->shap-e==0.0.0) (3.18.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from blobfile->shap-e==0.0.0) (2.0.4)\r\n",
      "Requirement already satisfied: lxml~=4.9 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from blobfile->shap-e==0.0.0) (4.9.3)\r\n",
      "Requirement already satisfied: ftfy in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (6.1.1)\r\n",
      "Requirement already satisfied: regex in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (2023.8.8)\r\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (0.15.2)\r\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from fire->shap-e==0.0.0) (1.16.0)\r\n",
      "Requirement already satisfied: termcolor in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from fire->shap-e==0.0.0) (2.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from matplotlib->shap-e==0.0.0) (1.1.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from matplotlib->shap-e==0.0.0) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from matplotlib->shap-e==0.0.0) (4.42.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from matplotlib->shap-e==0.0.0) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from matplotlib->shap-e==0.0.0) (23.1)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from matplotlib->shap-e==0.0.0) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from matplotlib->shap-e==0.0.0) (2.8.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from requests->shap-e==0.0.0) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from requests->shap-e==0.0.0) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from requests->shap-e==0.0.0) (2023.7.22)\r\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from scikit-image->shap-e==0.0.0) (3.1)\r\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from scikit-image->shap-e==0.0.0) (2.31.1)\r\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from scikit-image->shap-e==0.0.0) (2023.8.12)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from scikit-image->shap-e==0.0.0) (1.4.1)\r\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from scikit-image->shap-e==0.0.0) (0.3)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from torch->shap-e==0.0.0) (4.7.1)\r\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from torch->shap-e==0.0.0) (1.12)\r\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from torch->shap-e==0.0.0) (3.1.2)\r\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from ftfy->clip@ git+https://github.com/openai/CLIP.git->shap-e==0.0.0) (0.2.6)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from jinja2->torch->shap-e==0.0.0) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages (from sympy->torch->shap-e==0.0.0) (1.3.0)\r\n",
      "Installing collected packages: shap-e\r\n",
      "  Attempting uninstall: shap-e\r\n",
      "    Found existing installation: shap-e 0.0.0\r\n",
      "    Uninstalling shap-e-0.0.0:\r\n",
      "      Successfully uninstalled shap-e-0.0.0\r\n",
      "  Running setup.py develop for shap-e\r\n",
      "Successfully installed shap-e-0.0.0\r\n"
     ]
    }
   ],
   "source": [
    "%cd shap-e\n",
    "!pip install -e ."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T17:16:28.022036Z",
     "start_time": "2023-08-13T17:16:22.685357Z"
    }
   },
   "id": "fa03d881da74e17f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-13T17:18:42.901648Z",
     "start_time": "2023-08-13T17:18:42.893145Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from shap_e.diffusion.sample import sample_latents\n",
    "from shap_e.diffusion.gaussian_diffusion import diffusion_from_config\n",
    "from shap_e.models.download import load_model, load_config\n",
    "from shap_e.util.notebooks import create_pan_cameras, decode_latent_images, gif_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T17:18:46.537845Z",
     "start_time": "2023-08-13T17:18:46.532182Z"
    }
   },
   "id": "a8a224fbb9ec0589"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "xm = load_model('transmitter', device=device) \n",
    "model = load_model('text300M', device=device) \n",
    "diffusion = diffusion_from_config(load_config('diffusion')) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T17:19:27.260697Z",
     "start_time": "2023-08-13T17:18:52.810464Z"
    }
   },
   "id": "322a63b2e704f4b8"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/64 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daee3b7502c347ce8ce28d83eda9eb11"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m guidance_scale \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m15.0\u001B[39m \u001B[38;5;66;03m# this is the scale of the guidance, higher values make the model look more like the prompt.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma donut\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;66;03m# this is the prompt, you can change this to anything you want.\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m latents \u001B[38;5;241m=\u001B[39m \u001B[43msample_latents\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdiffusion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiffusion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mguidance_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mguidance_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprogress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclip_denoised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_fp16\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_karras\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkarras_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43msigma_min\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1E-3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43msigma_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m160\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43ms_churn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/sample.py:62\u001B[0m, in \u001B[0;36msample_latents\u001B[0;34m(batch_size, model, diffusion, model_kwargs, guidance_scale, clip_denoised, use_fp16, use_karras, karras_steps, sigma_min, sigma_max, s_churn, device, progress)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautocast(device_type\u001B[38;5;241m=\u001B[39mdevice\u001B[38;5;241m.\u001B[39mtype, enabled\u001B[38;5;241m=\u001B[39muse_fp16):\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_karras:\n\u001B[0;32m---> 62\u001B[0m         samples \u001B[38;5;241m=\u001B[39m \u001B[43mkarras_sample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdiffusion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiffusion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[43m            \u001B[49m\u001B[43mshape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_shape\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[43m            \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkarras_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     67\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclip_denoised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclip_denoised\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m            \u001B[49m\u001B[43msigma_min\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msigma_min\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m            \u001B[49m\u001B[43msigma_max\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msigma_max\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m            \u001B[49m\u001B[43ms_churn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ms_churn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m            \u001B[49m\u001B[43mguidance_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mguidance_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     77\u001B[0m         internal_batch_size \u001B[38;5;241m=\u001B[39m batch_size\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/k_diffusion.py:113\u001B[0m, in \u001B[0;36mkarras_sample\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mkarras_sample\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    112\u001B[0m     last \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m karras_sample_progressive(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m         last \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m last\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/k_diffusion.py:181\u001B[0m, in \u001B[0;36mkarras_sample_progressive\u001B[0;34m(diffusion, model, shape, steps, clip_denoised, progress, model_kwargs, device, sigma_min, sigma_max, rho, sampler, s_churn, s_tmin, s_tmax, s_noise, guidance_scale)\u001B[0m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    179\u001B[0m     guided_denoiser \u001B[38;5;241m=\u001B[39m denoiser\n\u001B[0;32m--> 181\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m sample_fn(\n\u001B[1;32m    182\u001B[0m     guided_denoiser,\n\u001B[1;32m    183\u001B[0m     x_T,\n\u001B[1;32m    184\u001B[0m     sigmas,\n\u001B[1;32m    185\u001B[0m     progress\u001B[38;5;241m=\u001B[39mprogress,\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msampler_args,\n\u001B[1;32m    187\u001B[0m ):\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(diffusion, GaussianDiffusion):\n\u001B[1;32m    189\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m diffusion\u001B[38;5;241m.\u001B[39munscale_out_dict(obj)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/utils/_contextlib.py:35\u001B[0m, in \u001B[0;36m_wrap_generator.<locals>.generator_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m---> 35\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/k_diffusion.py:265\u001B[0m, in \u001B[0;36msample_heun\u001B[0;34m(denoiser, x, sigmas, progress, s_churn, s_tmin, s_tmax, s_noise)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m gamma \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    264\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m eps \u001B[38;5;241m*\u001B[39m (sigma_hat\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m-\u001B[39m sigmas[i] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n\u001B[0;32m--> 265\u001B[0m denoised \u001B[38;5;241m=\u001B[39m \u001B[43mdenoiser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma_hat\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43ms_in\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    266\u001B[0m d \u001B[38;5;241m=\u001B[39m to_d(x, sigma_hat, denoised)\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m\"\u001B[39m: x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mi\u001B[39m\u001B[38;5;124m\"\u001B[39m: i, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msigma\u001B[39m\u001B[38;5;124m\"\u001B[39m: sigmas[i], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msigma_hat\u001B[39m\u001B[38;5;124m\"\u001B[39m: sigma_hat, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpred_xstart\u001B[39m\u001B[38;5;124m\"\u001B[39m: denoised}\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/k_diffusion.py:173\u001B[0m, in \u001B[0;36mkarras_sample_progressive.<locals>.guided_denoiser\u001B[0;34m(x_t, sigma)\u001B[0m\n\u001B[1;32m    171\u001B[0m x_t \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mcat([x_t, x_t], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    172\u001B[0m sigma \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mcat([sigma, sigma], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 173\u001B[0m x_0 \u001B[38;5;241m=\u001B[39m \u001B[43mdenoiser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m cond_x_0, uncond_x_0 \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39msplit(x_0, \u001B[38;5;28mlen\u001B[39m(x_0) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    175\u001B[0m x_0 \u001B[38;5;241m=\u001B[39m uncond_x_0 \u001B[38;5;241m+\u001B[39m guidance_scale \u001B[38;5;241m*\u001B[39m (cond_x_0 \u001B[38;5;241m-\u001B[39m uncond_x_0)\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/k_diffusion.py:160\u001B[0m, in \u001B[0;36mkarras_sample_progressive.<locals>.denoiser\u001B[0;34m(x_t, sigma)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdenoiser\u001B[39m(x_t, sigma):\n\u001B[0;32m--> 160\u001B[0m     _, denoised \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdenoise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip_denoised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclip_denoised\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m denoised\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/k_diffusion.py:105\u001B[0m, in \u001B[0;36mGaussianToKarrasDenoiser.denoise\u001B[0;34m(self, x_t, sigmas, clip_denoised, model_kwargs)\u001B[0m\n\u001B[1;32m     99\u001B[0m t \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mtensor(\n\u001B[1;32m    100\u001B[0m     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msigma_to_t(sigma) \u001B[38;5;28;01mfor\u001B[39;00m sigma \u001B[38;5;129;01min\u001B[39;00m sigmas\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()],\n\u001B[1;32m    101\u001B[0m     dtype\u001B[38;5;241m=\u001B[39mth\u001B[38;5;241m.\u001B[39mlong,\n\u001B[1;32m    102\u001B[0m     device\u001B[38;5;241m=\u001B[39msigmas\u001B[38;5;241m.\u001B[39mdevice,\n\u001B[1;32m    103\u001B[0m )\n\u001B[1;32m    104\u001B[0m c_in \u001B[38;5;241m=\u001B[39m append_dims(\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m (sigmas\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m, x_t\u001B[38;5;241m.\u001B[39mndim)\n\u001B[0;32m--> 105\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdiffusion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mp_mean_variance\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mc_in\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip_denoised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclip_denoised\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, out[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpred_xstart\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/diffusion/gaussian_diffusion.py:333\u001B[0m, in \u001B[0;36mGaussianDiffusion.p_mean_variance\u001B[0;34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001B[0m\n\u001B[1;32m    331\u001B[0m B, C \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[:\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m t\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m==\u001B[39m (B,)\n\u001B[0;32m--> 333\u001B[0m model_output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(model_output, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    335\u001B[0m     model_output, extra \u001B[38;5;241m=\u001B[39m model_output\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/generation/latent_diffusion.py:21\u001B[0m, in \u001B[0;36mSplitVectorDiffusion.forward\u001B[0;34m(self, x, t, **kwargs)\u001B[0m\n\u001B[1;32m     19\u001B[0m h \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mreshape(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_ctx, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     20\u001B[0m pre_channels \u001B[38;5;241m=\u001B[39m h\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m---> 21\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m     23\u001B[0m     h\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m pre_channels \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m     24\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected twice as many outputs for variance prediction\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     25\u001B[0m eps, var \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mchunk(h, \u001B[38;5;241m2\u001B[39m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/generation/transformer.py:298\u001B[0m, in \u001B[0;36mCLIPImagePointDiffusionTransformer.forward\u001B[0;34m(self, x, t, images, texts, embeddings)\u001B[0m\n\u001B[1;32m    295\u001B[0m clip_embed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclip_embed(clip_out)\n\u001B[1;32m    297\u001B[0m cond \u001B[38;5;241m=\u001B[39m [(clip_embed, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtoken_cond), (t_embed, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_token_cond)]\n\u001B[0;32m--> 298\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_with_cond\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/generation/transformer.py:231\u001B[0m, in \u001B[0;36mPointDiffusionTransformer._forward_with_cond\u001B[0;34m(self, x, cond_as_token)\u001B[0m\n\u001B[1;32m    228\u001B[0m     h \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(extra_tokens \u001B[38;5;241m+\u001B[39m [h], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    230\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_pre(h)\n\u001B[0;32m--> 231\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_post(h)\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(extra_tokens):\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/generation/transformer.py:147\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresblocks:\n\u001B[0;32m--> 147\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/generation/transformer.py:109\u001B[0m, in \u001B[0;36mResidualAttentionBlock.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m--> 109\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mln_1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_2(x))\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/generation/transformer.py:42\u001B[0m, in \u001B[0;36mMultiheadAttention.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     41\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc_qkv(x)\n\u001B[0;32m---> 42\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mcheckpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     43\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mc_proj(x)\n\u001B[1;32m     44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/nn/checkpoint.py:24\u001B[0m, in \u001B[0;36mcheckpoint\u001B[0;34m(func, inputs, params, flag)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m flag:\n\u001B[1;32m     23\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(inputs) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mtuple\u001B[39m(params)\n\u001B[0;32m---> 24\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mCheckpointFunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39minputs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/autograd/function.py:506\u001B[0m, in \u001B[0;36mFunction.apply\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_are_functorch_transforms_active():\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001B[39;00m\n\u001B[1;32m    505\u001B[0m     args \u001B[38;5;241m=\u001B[39m _functorch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39munwrap_dead_wrappers(args)\n\u001B[0;32m--> 506\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39msetup_context \u001B[38;5;241m==\u001B[39m _SingleLevelFunction\u001B[38;5;241m.\u001B[39msetup_context:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    510\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIn order to use an autograd.Function with functorch transforms \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    511\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    512\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstaticmethod. For more details, please see \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/cuda/amp/autocast_mode.py:98\u001B[0m, in \u001B[0;36mcustom_fwd.<locals>.decorate_fwd\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cast_inputs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     97\u001B[0m     args[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fwd_used_autocast \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mis_autocast_enabled()\n\u001B[0;32m---> 98\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfwd\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    100\u001B[0m     autocast_context \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mis_autocast_enabled()\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/nn/checkpoint.py:39\u001B[0m, in \u001B[0;36mCheckpointFunction.forward\u001B[0;34m(ctx, run_function, length, *args)\u001B[0m\n\u001B[1;32m     37\u001B[0m ctx\u001B[38;5;241m.\u001B[39msave_for_backward(\u001B[38;5;241m*\u001B[39minput_tensors, \u001B[38;5;241m*\u001B[39minput_params)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 39\u001B[0m     output_tensors \u001B[38;5;241m=\u001B[39m \u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_tensors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m output_tensors\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/3d-generation/shap-e/shap_e/models/generation/transformer.py:80\u001B[0m, in \u001B[0;36mQKVMultiheadAttention.forward\u001B[0;34m(self, qkv)\u001B[0m\n\u001B[1;32m     78\u001B[0m wdtype \u001B[38;5;241m=\u001B[39m weight\u001B[38;5;241m.\u001B[39mdtype\n\u001B[1;32m     79\u001B[0m weight \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msoftmax(weight\u001B[38;5;241m.\u001B[39mfloat(), dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mtype(wdtype)\n\u001B[0;32m---> 80\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbhts,bshc->bthc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(bs, n_ctx, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/3d-generation/lib/python3.10/site-packages/torch/functional.py:378\u001B[0m, in \u001B[0;36meinsum\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m einsum(equation, \u001B[38;5;241m*\u001B[39m_operands)\n\u001B[1;32m    375\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(operands) \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m opt_einsum\u001B[38;5;241m.\u001B[39menabled:\n\u001B[1;32m    376\u001B[0m     \u001B[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001B[39;00m\n\u001B[1;32m    377\u001B[0m     \u001B[38;5;66;03m# or the user has disabled using opt_einsum\u001B[39;00m\n\u001B[0;32m--> 378\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meinsum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mequation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperands\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    380\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m opt_einsum\u001B[38;5;241m.\u001B[39mis_available():\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1 # this is the size of the models, higher values take longer to generate.\n",
    "guidance_scale = 15.0 # this is the scale of the guidance, higher values make the model look more like the prompt.\n",
    "prompt = \"a donut\" # this is the prompt, you can change this to anything you want.\n",
    "\n",
    "latents = sample_latents(\n",
    "    batch_size=batch_size,\n",
    "    model=model,\n",
    "    diffusion=diffusion,\n",
    "    guidance_scale=guidance_scale,\n",
    "    model_kwargs=dict(texts=[prompt] * batch_size),\n",
    "    progress=True,\n",
    "    clip_denoised=True,\n",
    "    use_fp16=True,\n",
    "    use_karras=True,\n",
    "    karras_steps=64,\n",
    "    sigma_min=1E-3,\n",
    "    sigma_max=160,\n",
    "    s_churn=0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T17:23:13.284645Z",
     "start_time": "2023-08-13T17:19:49.421453Z"
    }
   },
   "id": "eec21aee17ce1f37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "render_mode = 'nerf' # you can change this to 'stf'\n",
    "size = 64 # this is the size of the renders, higher values take longer to render.\n",
    "\n",
    "cameras = create_pan_cameras(size, device)\n",
    "for i, latent in enumerate(latents):\n",
    "    images = decode_latent_images(xm, latent, cameras, rendering_mode=render_mode)\n",
    "    display(gif_widget(images))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-13T15:54:05.623886Z"
    }
   },
   "id": "66bc58d2eb31b72e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example of saving the latents as meshes.\n",
    "from shap_e.util.notebooks import decode_latent_mesh\n",
    "\n",
    "for i, latent in enumerate(latents):\n",
    "    t = decode_latent_mesh(xm, latent).tri_mesh()\n",
    "    with open(f'example_mesh_{i}.ply', 'wb') as f: # this is three-dimensional geometric data of model.\n",
    "        t.write_ply(f)\n",
    "    with open(f'example_mesh_{i}.obj', 'w') as f: # we will use this file to customize in Blender Studio later.\n",
    "        t.write_obj(f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-13T15:54:05.625684Z"
    }
   },
   "id": "a87983fe965776d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5fdff0261fc0cf9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
